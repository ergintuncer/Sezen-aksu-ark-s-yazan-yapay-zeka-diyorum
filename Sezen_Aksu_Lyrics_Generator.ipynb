{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sezen_Aksu_Lyrics_Generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ergintuncer/Sezen-aksu-ark-s-yazan-yapay-zeka-diyorum/blob/master/Sezen_Aksu_Lyrics_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qPuWu-ObJNpO",
        "colab": {},
        "outputId": "3fb23bba-466d-4572-83b1-e3d196cd732f"
      },
      "cell_type": "code",
      "source": [
        "# Gerekli kütüphaneleri import edelim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys \n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed, CuDNNLSTM,BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\ergin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QX1GxeotmWKG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# verisetini yükleyelim\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ByuX75lRJNpW",
        "outputId": "c977f79d-dff9-4686-dc7a-f8cfda91130d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "# yüklenen verisetini seçelim\n",
        "dataset = pd.read_csv('Sezen Aksu.csv', encoding = \"utf_8\")\n",
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sanatçı Adı</th>\n",
              "      <th>Şarkı Id</th>\n",
              "      <th>Şarkı Adı</th>\n",
              "      <th>Şarkı Sözü</th>\n",
              "      <th>Satır No</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sezen Aksu</td>\n",
              "      <td>1</td>\n",
              "      <td>1945</td>\n",
              "      <td>Bin Dokuzyüz Kırkbeş</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sezen Aksu</td>\n",
              "      <td>1</td>\n",
              "      <td>1945</td>\n",
              "      <td>Gel asırlardan uzanda tut ellerimi sımsıcak</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sezen Aksu</td>\n",
              "      <td>1</td>\n",
              "      <td>1945</td>\n",
              "      <td>Yoksa bendeki çocukda böyle çaresiz kalacak</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sezen Aksu</td>\n",
              "      <td>1</td>\n",
              "      <td>1945</td>\n",
              "      <td>Öfke ile beslenen çocuklar yalnızdırlar</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sezen Aksu</td>\n",
              "      <td>1</td>\n",
              "      <td>1945</td>\n",
              "      <td>Ve ümitleri çiçeklerden acıları tarihlerden</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Sanatçı Adı  Şarkı Id Şarkı Adı  \\\n",
              "0  Sezen Aksu         1      1945   \n",
              "1  Sezen Aksu         1      1945   \n",
              "2  Sezen Aksu         1      1945   \n",
              "3  Sezen Aksu         1      1945   \n",
              "4  Sezen Aksu         1      1945   \n",
              "\n",
              "                                    Şarkı Sözü  Satır No  \n",
              "0                         Bin Dokuzyüz Kırkbeş         1  \n",
              "1  Gel asırlardan uzanda tut ellerimi sımsıcak         2  \n",
              "2  Yoksa bendeki çocukda böyle çaresiz kalacak         3  \n",
              "3      Öfke ile beslenen çocuklar yalnızdırlar         4  \n",
              "4  Ve ümitleri çiçeklerden acıları tarihlerden         5  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7B5Td0JcJNpa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def processFirstLine(lyrics, songID, songName, row):\n",
        "    lyrics.append(row['Şarkı Sözü'] + '\\n')\n",
        "    songID.append(row['Şarkı Id'])\n",
        "    songName.append(row['Şarkı Adı'])\n",
        "    return lyrics,songID,songName\n",
        "  \n",
        "# Boş listeleri tanımlayalım (lyrics , songID , songName) \n",
        "lyrics = []\n",
        "songID = []\n",
        "songName = []\n",
        "\n",
        "# songNumber verisetindeki şarkının sırasını belirtir.\n",
        "songNumber = 1\n",
        "# i veisetindeki şarkı sözünün sırasını belirtir.\n",
        "i = 0\n",
        "isFirstLine = True\n",
        "# Her bir satırdaki verileri sırası ile birleştirelim.\n",
        "for index,row in dataset.iterrows():\n",
        "    if(songNumber == row['Şarkı Id']):\n",
        "        if (isFirstLine):\n",
        "            lyrics,songID,songName = processFirstLine(lyrics,songID,songName,row)\n",
        "            isFirstLine = False\n",
        "        else :\n",
        "            # Eğer aynı şarkıdaysak birleştirmeye devam edelim  \n",
        "            lyrics[i] +=  row['Şarkı Sözü'] + '\\n'\n",
        "    # Aynı şarkı için söz birleştirme işlemi bittiyse bir sonrarki şarkıya geç:   \n",
        "    else :\n",
        "        lyrics,songID,songName = processFirstLine(lyrics,songID,songName,row)\n",
        "        songNumber = row['Şarkı Id']\n",
        "        i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bsmQGKXSJNpg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sözleri .txt dosyasına kaydedelim\n",
        "with open('lyricsText.txt', 'w',encoding=\"utf-8\") as filehandle:  \n",
        "    for listitem in lyrics:\n",
        "        filehandle.write('%s\\n' % listitem)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "maXVqEH4JNpj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# yeni verisetini yükle ve tüm karakterleri küçük harfe dönüştür :\n",
        "textFileName = 'lyricsText.txt'\n",
        "raw_text = open(textFileName, encoding = 'UTF-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bVNqdjcqJNpm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# her harfi int türünde dönüştürelim\n",
        "chars = sorted(list(set(raw_text)))\n",
        "int_chars = dict((i, c) for i, c in enumerate(chars))\n",
        "chars_int = dict((i, c) for c, i in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VOg49JcNJNpp",
        "outputId": "825a05cf-2971-4eec-b46c-d568c6f6852e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print('Toplam karakter sayısı :'  , n_chars) # number of all the characters in lyricsText.txt dosyasındaki tüm harf sayısı\n",
        "print('Unique karakter sayısı : ', n_vocab) # farklı harakter sayısı"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Toplam karakter sayısı : 340460\n",
            "Unique karakter sayısı :  61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lE6jeAF1JNpu",
        "outputId": "20aee7f1-ac78-4bf0-ae7f-fbb8fcbb932f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "# verisetinin işlenmesi:\n",
        "seq_len = 32\n",
        "data_X = []\n",
        "data_y = []\n",
        "for i in range(0, n_chars - seq_len, 1):\n",
        "    # Input Sequeance(Input olarak kullanılacak)\n",
        "    seq_in  = raw_text[i:i+seq_len]\n",
        "    # Output sequence (Target olarak kullanılacak)\n",
        "    seq_out = raw_text[i + seq_len]\n",
        "    # Input verisini data_X olarak saklayalım\n",
        "    data_X.append([chars_int[char] for char in seq_in])\n",
        "    # Target verilerini data_y olarak saklayalım\n",
        "    data_y.append(chars_int[seq_out])\n",
        "n_patterns = len(data_X)\n",
        "print( 'Eğitim setindeki toplam veri sayısı : ', n_patterns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eğitim setindeki toplam veri sayısı :  340428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tslL5zbqJNp0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data_x verisinin LSTM RNN' de işlenecek şekilde yeniden düzenlenmesi:\n",
        "X = np.reshape(data_X , (n_patterns, seq_len, 1))\n",
        "# verilerin normalize edilmesi:\n",
        "X = X/ float(n_vocab)\n",
        "# Target verisi için One hot encoding:\n",
        "y = np_utils.to_categorical(data_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sqzBcM5XEAE2",
        "colab_type": "code",
        "colab": {},
        "outputId": "1fcf59a0-a4ba-4741-de9a-2a5271c436e2"
      },
      "cell_type": "code",
      "source": [
        "# eğitim ve test verilerini oluşturalım\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=64)\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(306385, 32, 1) (306385, 61)\n",
            "(34043, 32, 1) (34043, 61)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SVG05bNUJNp4",
        "outputId": "4dcc5069-9501-4fd7-c08d-d5540b38e2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "cell_type": "code",
      "source": [
        "# modelin oluşturulması \n",
        "model = Sequential()\n",
        "\n",
        "model.add(CuDNNLSTM(512, input_shape =(X_train.shape[1], X_train.shape[2]), return_sequences = True,name='input'))\n",
        "model.add(BatchNormalization(name='BatchNorm'))\n",
        "model.add(CuDNNLSTM(512, return_sequences=True, name='CuDNNLSTM'))\n",
        "    \n",
        "model.add(Flatten(name='Flatten'))\n",
        "\n",
        "model.add(Dense(y.shape[1],name='FullyConnected'))\n",
        "model.add(Activation('softmax',name='output'))\n",
        "\n",
        "adam=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (CuDNNLSTM)            (None, 32, 512)           1054720   \n",
            "_________________________________________________________________\n",
            "BatchNorm (BatchNormalizatio (None, 32, 512)           2048      \n",
            "_________________________________________________________________\n",
            "CuDNNLSTM (CuDNNLSTM)        (None, 32, 512)           2101248   \n",
            "_________________________________________________________________\n",
            "Flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "FullyConnected (Dense)       (None, 61)                999485    \n",
            "_________________________________________________________________\n",
            "output (Activation)          (None, 61)                0         \n",
            "=================================================================\n",
            "Total params: 4,157,501\n",
            "Trainable params: 4,156,477\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EU4NsmMgJNp9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Checkpoit oluşturalım :\n",
        "checkpoint_name = 'Sezen-Aksu-Epoch_{epoch:02d}-Acc_{acc:.2f}-Val_Acc_{val_acc:.2f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='loss', verbose = 1, save_best_only = True, mode ='min')\n",
        "\n",
        "#Modelin gelişimi grafiksel olarak görmek için tensorboar kullanalım\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()),\n",
        "                          write_graph=False,\n",
        "                          write_images=True,\n",
        "                          batch_size = 1024,\n",
        "                          write_grads=True)\n",
        "\n",
        "# Model gelişim göstermezse daha fazla vakit kaybetmeyelim \n",
        "earlyStopping=EarlyStopping(monitor='val_loss', \n",
        "                              min_delta=0, \n",
        "                              patience=3, \n",
        "                              verbose=1,\n",
        "                              mode='auto', \n",
        "                              baseline=None, \n",
        "                              restore_best_weights=False)\n",
        "\n",
        "callbacks_list = [checkpoint,earlyStopping,tensorboard]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8-IvCKC_JNqA",
        "outputId": "880a639f-4f28-41fd-f585-12a374fb7f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "cell_type": "code",
      "source": [
        "# Modeli eğitelim :\n",
        "history = model.fit(X_train,  y_train,\n",
        "                    epochs = 150,\n",
        "                    batch_size = 1024,\n",
        "                    callbacks= callbacks_list,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (X_test, y_test),\n",
        "                    initial_epoch = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 306385 samples, validate on 34043 samples\n",
            "Epoch 1/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 3.0673 - acc: 0.1379 - val_loss: 2.9531 - val_acc: 0.1634\n",
            "\n",
            "Epoch 00001: loss improved from inf to 3.06729, saving model to Sezen-Aksu-Epoch_01-Acc_0.14-Val_Acc_0.16.hdf5\n",
            "Epoch 2/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.8149 - acc: 0.1774 - val_loss: 2.8241 - val_acc: 0.1720\n",
            "\n",
            "Epoch 00002: loss improved from 3.06729 to 2.81495, saving model to Sezen-Aksu-Epoch_02-Acc_0.18-Val_Acc_0.17.hdf5\n",
            "Epoch 3/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.7369 - acc: 0.1848 - val_loss: 2.6999 - val_acc: 0.1933\n",
            "\n",
            "Epoch 00003: loss improved from 2.81495 to 2.73694, saving model to Sezen-Aksu-Epoch_03-Acc_0.18-Val_Acc_0.19.hdf5\n",
            "Epoch 4/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.6612 - acc: 0.1983 - val_loss: 2.6849 - val_acc: 0.1946\n",
            "\n",
            "Epoch 00004: loss improved from 2.73694 to 2.66118, saving model to Sezen-Aksu-Epoch_04-Acc_0.20-Val_Acc_0.19.hdf5\n",
            "Epoch 5/150\n",
            "306385/306385 [==============================] - 120s 393us/step - loss: 2.5874 - acc: 0.2173 - val_loss: 2.5845 - val_acc: 0.2234\n",
            "\n",
            "Epoch 00005: loss improved from 2.66118 to 2.58742, saving model to Sezen-Aksu-Epoch_05-Acc_0.22-Val_Acc_0.22.hdf5\n",
            "Epoch 6/150\n",
            "306385/306385 [==============================] - 120s 393us/step - loss: 2.5169 - acc: 0.2375 - val_loss: 2.5193 - val_acc: 0.2415\n",
            "\n",
            "Epoch 00006: loss improved from 2.58742 to 2.51689, saving model to Sezen-Aksu-Epoch_06-Acc_0.24-Val_Acc_0.24.hdf5\n",
            "Epoch 7/150\n",
            "306385/306385 [==============================] - 120s 393us/step - loss: 2.4543 - acc: 0.2561 - val_loss: 2.5635 - val_acc: 0.2211\n",
            "\n",
            "Epoch 00007: loss improved from 2.51689 to 2.45428, saving model to Sezen-Aksu-Epoch_07-Acc_0.26-Val_Acc_0.22.hdf5\n",
            "Epoch 8/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.3974 - acc: 0.2740 - val_loss: 2.4208 - val_acc: 0.2664\n",
            "\n",
            "Epoch 00008: loss improved from 2.45428 to 2.39738, saving model to Sezen-Aksu-Epoch_08-Acc_0.27-Val_Acc_0.27.hdf5\n",
            "Epoch 9/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.3412 - acc: 0.2916 - val_loss: 2.3589 - val_acc: 0.2884\n",
            "\n",
            "Epoch 00009: loss improved from 2.39738 to 2.34121, saving model to Sezen-Aksu-Epoch_09-Acc_0.29-Val_Acc_0.29.hdf5\n",
            "Epoch 10/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.2858 - acc: 0.3112 - val_loss: 2.3401 - val_acc: 0.2971\n",
            "\n",
            "Epoch 00010: loss improved from 2.34121 to 2.28585, saving model to Sezen-Aksu-Epoch_10-Acc_0.31-Val_Acc_0.30.hdf5\n",
            "Epoch 11/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.2321 - acc: 0.3284 - val_loss: 2.2634 - val_acc: 0.3249\n",
            "\n",
            "Epoch 00011: loss improved from 2.28585 to 2.23208, saving model to Sezen-Aksu-Epoch_11-Acc_0.33-Val_Acc_0.32.hdf5\n",
            "Epoch 12/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.1788 - acc: 0.3460 - val_loss: 2.2343 - val_acc: 0.3321\n",
            "\n",
            "Epoch 00012: loss improved from 2.23208 to 2.17879, saving model to Sezen-Aksu-Epoch_12-Acc_0.35-Val_Acc_0.33.hdf5\n",
            "Epoch 13/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.1270 - acc: 0.3622 - val_loss: 2.1930 - val_acc: 0.3464\n",
            "\n",
            "Epoch 00013: loss improved from 2.17879 to 2.12700, saving model to Sezen-Aksu-Epoch_13-Acc_0.36-Val_Acc_0.35.hdf5\n",
            "Epoch 14/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.0765 - acc: 0.3788 - val_loss: 2.1885 - val_acc: 0.3448\n",
            "\n",
            "Epoch 00014: loss improved from 2.12700 to 2.07654, saving model to Sezen-Aksu-Epoch_14-Acc_0.38-Val_Acc_0.34.hdf5\n",
            "Epoch 15/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 2.0265 - acc: 0.3947 - val_loss: 2.1212 - val_acc: 0.3692\n",
            "\n",
            "Epoch 00015: loss improved from 2.07654 to 2.02650, saving model to Sezen-Aksu-Epoch_15-Acc_0.39-Val_Acc_0.37.hdf5\n",
            "Epoch 16/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 1.9774 - acc: 0.4114 - val_loss: 2.0907 - val_acc: 0.3763\n",
            "\n",
            "Epoch 00016: loss improved from 2.02650 to 1.97745, saving model to Sezen-Aksu-Epoch_16-Acc_0.41-Val_Acc_0.38.hdf5\n",
            "Epoch 17/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 1.9288 - acc: 0.4274 - val_loss: 2.0415 - val_acc: 0.3954\n",
            "\n",
            "Epoch 00017: loss improved from 1.97745 to 1.92878, saving model to Sezen-Aksu-Epoch_17-Acc_0.43-Val_Acc_0.40.hdf5\n",
            "Epoch 18/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 1.8823 - acc: 0.4414 - val_loss: 2.0068 - val_acc: 0.4065\n",
            "\n",
            "Epoch 00018: loss improved from 1.92878 to 1.88226, saving model to Sezen-Aksu-Epoch_18-Acc_0.44-Val_Acc_0.41.hdf5\n",
            "Epoch 19/150\n",
            "306385/306385 [==============================] - 120s 393us/step - loss: 1.8342 - acc: 0.4578 - val_loss: 1.9716 - val_acc: 0.4144\n",
            "\n",
            "Epoch 00019: loss improved from 1.88226 to 1.83422, saving model to Sezen-Aksu-Epoch_19-Acc_0.46-Val_Acc_0.41.hdf5\n",
            "Epoch 20/150\n",
            "306385/306385 [==============================] - 120s 392us/step - loss: 1.7899 - acc: 0.4719 - val_loss: 1.9644 - val_acc: 0.4170\n",
            "\n",
            "Epoch 00020: loss improved from 1.83422 to 1.78988, saving model to Sezen-Aksu-Epoch_20-Acc_0.47-Val_Acc_0.42.hdf5\n",
            "Epoch 21/150\n",
            "306385/306385 [==============================] - 120s 393us/step - loss: 1.7451 - acc: 0.4867 - val_loss: 1.9148 - val_acc: 0.4312\n",
            "\n",
            "Epoch 00021: loss improved from 1.78988 to 1.74508, saving model to Sezen-Aksu-Epoch_21-Acc_0.49-Val_Acc_0.43.hdf5\n",
            "Epoch 22/150\n",
            "306385/306385 [==============================] - 120s 393us/step - loss: 1.6996 - acc: 0.5020 - val_loss: 1.8837 - val_acc: 0.4414\n",
            "\n",
            "Epoch 00022: loss improved from 1.74508 to 1.69965, saving model to Sezen-Aksu-Epoch_22-Acc_0.50-Val_Acc_0.44.hdf5\n",
            "Epoch 23/150\n",
            "306385/306385 [==============================] - 120s 393us/step - loss: 1.6553 - acc: 0.5162 - val_loss: 1.8617 - val_acc: 0.4477\n",
            "\n",
            "Epoch 00023: loss improved from 1.69965 to 1.65527, saving model to Sezen-Aksu-Epoch_23-Acc_0.52-Val_Acc_0.45.hdf5\n",
            "Epoch 24/150\n",
            "306385/306385 [==============================] - 121s 393us/step - loss: 1.6141 - acc: 0.5289 - val_loss: 1.8994 - val_acc: 0.4357\n",
            "\n",
            "Epoch 00024: loss improved from 1.65527 to 1.61414, saving model to Sezen-Aksu-Epoch_24-Acc_0.53-Val_Acc_0.44.hdf5\n",
            "Epoch 25/150\n",
            "306385/306385 [==============================] - 120s 393us/step - loss: 1.5714 - acc: 0.5430 - val_loss: 1.7996 - val_acc: 0.4701\n",
            "\n",
            "Epoch 00025: loss improved from 1.61414 to 1.57135, saving model to Sezen-Aksu-Epoch_25-Acc_0.54-Val_Acc_0.47.hdf5\n",
            "Epoch 26/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 1.5300 - acc: 0.5582 - val_loss: 1.7838 - val_acc: 0.4746\n",
            "\n",
            "Epoch 00026: loss improved from 1.57135 to 1.53003, saving model to Sezen-Aksu-Epoch_26-Acc_0.56-Val_Acc_0.47.hdf5\n",
            "Epoch 27/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 1.4915 - acc: 0.5702 - val_loss: 1.7417 - val_acc: 0.4873\n",
            "\n",
            "Epoch 00027: loss improved from 1.53003 to 1.49150, saving model to Sezen-Aksu-Epoch_27-Acc_0.57-Val_Acc_0.49.hdf5\n",
            "Epoch 28/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 1.4506 - acc: 0.5834 - val_loss: 1.7377 - val_acc: 0.4860\n",
            "\n",
            "Epoch 00028: loss improved from 1.49150 to 1.45061, saving model to Sezen-Aksu-Epoch_28-Acc_0.58-Val_Acc_0.49.hdf5\n",
            "Epoch 29/150\n",
            "306385/306385 [==============================] - 121s 396us/step - loss: 1.4107 - acc: 0.5968 - val_loss: 1.7739 - val_acc: 0.4805\n",
            "\n",
            "Epoch 00029: loss improved from 1.45061 to 1.41071, saving model to Sezen-Aksu-Epoch_29-Acc_0.60-Val_Acc_0.48.hdf5\n",
            "Epoch 30/150\n",
            "306385/306385 [==============================] - 121s 396us/step - loss: 1.3716 - acc: 0.6101 - val_loss: 1.6680 - val_acc: 0.5106\n",
            "\n",
            "Epoch 00030: loss improved from 1.41071 to 1.37162, saving model to Sezen-Aksu-Epoch_30-Acc_0.61-Val_Acc_0.51.hdf5\n",
            "Epoch 31/150\n",
            "306385/306385 [==============================] - 122s 397us/step - loss: 1.3331 - acc: 0.6219 - val_loss: 1.6420 - val_acc: 0.5189\n",
            "\n",
            "Epoch 00031: loss improved from 1.37162 to 1.33310, saving model to Sezen-Aksu-Epoch_31-Acc_0.62-Val_Acc_0.52.hdf5\n",
            "Epoch 32/150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "306385/306385 [==============================] - 121s 396us/step - loss: 1.2958 - acc: 0.6346 - val_loss: 1.6247 - val_acc: 0.5263\n",
            "\n",
            "Epoch 00032: loss improved from 1.33310 to 1.29577, saving model to Sezen-Aksu-Epoch_32-Acc_0.63-Val_Acc_0.53.hdf5\n",
            "Epoch 33/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 1.2605 - acc: 0.6462 - val_loss: 1.6035 - val_acc: 0.5313\n",
            "\n",
            "Epoch 00033: loss improved from 1.29577 to 1.26046, saving model to Sezen-Aksu-Epoch_33-Acc_0.65-Val_Acc_0.53.hdf5\n",
            "Epoch 34/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 1.2232 - acc: 0.6580 - val_loss: 1.6504 - val_acc: 0.5157\n",
            "\n",
            "Epoch 00034: loss improved from 1.26046 to 1.22324, saving model to Sezen-Aksu-Epoch_34-Acc_0.66-Val_Acc_0.52.hdf5\n",
            "Epoch 35/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 1.1876 - acc: 0.6699 - val_loss: 1.5786 - val_acc: 0.5410\n",
            "\n",
            "Epoch 00035: loss improved from 1.22324 to 1.18763, saving model to Sezen-Aksu-Epoch_35-Acc_0.67-Val_Acc_0.54.hdf5\n",
            "Epoch 36/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 1.1533 - acc: 0.6816 - val_loss: 1.5407 - val_acc: 0.5535\n",
            "\n",
            "Epoch 00036: loss improved from 1.18763 to 1.15332, saving model to Sezen-Aksu-Epoch_36-Acc_0.68-Val_Acc_0.55.hdf5\n",
            "Epoch 37/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 1.1174 - acc: 0.6938 - val_loss: 1.5253 - val_acc: 0.5574\n",
            "\n",
            "Epoch 00037: loss improved from 1.15332 to 1.11739, saving model to Sezen-Aksu-Epoch_37-Acc_0.69-Val_Acc_0.56.hdf5\n",
            "Epoch 38/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 1.0851 - acc: 0.7041 - val_loss: 1.4920 - val_acc: 0.5673\n",
            "\n",
            "Epoch 00038: loss improved from 1.11739 to 1.08506, saving model to Sezen-Aksu-Epoch_38-Acc_0.70-Val_Acc_0.57.hdf5\n",
            "Epoch 39/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 1.0513 - acc: 0.7159 - val_loss: 1.4639 - val_acc: 0.5767\n",
            "\n",
            "Epoch 00039: loss improved from 1.08506 to 1.05127, saving model to Sezen-Aksu-Epoch_39-Acc_0.72-Val_Acc_0.58.hdf5\n",
            "Epoch 40/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 1.0187 - acc: 0.7266 - val_loss: 1.4609 - val_acc: 0.5775\n",
            "\n",
            "Epoch 00040: loss improved from 1.05127 to 1.01868, saving model to Sezen-Aksu-Epoch_40-Acc_0.73-Val_Acc_0.58.hdf5\n",
            "Epoch 41/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.9871 - acc: 0.7372 - val_loss: 1.4428 - val_acc: 0.5830\n",
            "\n",
            "Epoch 00041: loss improved from 1.01868 to 0.98714, saving model to Sezen-Aksu-Epoch_41-Acc_0.74-Val_Acc_0.58.hdf5\n",
            "Epoch 42/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.9551 - acc: 0.7478 - val_loss: 1.4083 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00042: loss improved from 0.98714 to 0.95507, saving model to Sezen-Aksu-Epoch_42-Acc_0.75-Val_Acc_0.59.hdf5\n",
            "Epoch 43/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.9237 - acc: 0.7579 - val_loss: 1.3986 - val_acc: 0.5955\n",
            "\n",
            "Epoch 00043: loss improved from 0.95507 to 0.92368, saving model to Sezen-Aksu-Epoch_43-Acc_0.76-Val_Acc_0.60.hdf5\n",
            "Epoch 44/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.8926 - acc: 0.7685 - val_loss: 1.3646 - val_acc: 0.6069\n",
            "\n",
            "Epoch 00044: loss improved from 0.92368 to 0.89262, saving model to Sezen-Aksu-Epoch_44-Acc_0.77-Val_Acc_0.61.hdf5\n",
            "Epoch 45/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.8632 - acc: 0.7784 - val_loss: 1.3628 - val_acc: 0.6103\n",
            "\n",
            "Epoch 00045: loss improved from 0.89262 to 0.86321, saving model to Sezen-Aksu-Epoch_45-Acc_0.78-Val_Acc_0.61.hdf5\n",
            "Epoch 46/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.8334 - acc: 0.7877 - val_loss: 1.3357 - val_acc: 0.6189\n",
            "\n",
            "Epoch 00046: loss improved from 0.86321 to 0.83336, saving model to Sezen-Aksu-Epoch_46-Acc_0.79-Val_Acc_0.62.hdf5\n",
            "Epoch 47/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.8051 - acc: 0.7969 - val_loss: 1.3647 - val_acc: 0.6088\n",
            "\n",
            "Epoch 00047: loss improved from 0.83336 to 0.80511, saving model to Sezen-Aksu-Epoch_47-Acc_0.80-Val_Acc_0.61.hdf5\n",
            "Epoch 48/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.7764 - acc: 0.8071 - val_loss: 1.3597 - val_acc: 0.6069\n",
            "\n",
            "Epoch 00048: loss improved from 0.80511 to 0.77643, saving model to Sezen-Aksu-Epoch_48-Acc_0.81-Val_Acc_0.61.hdf5\n",
            "Epoch 49/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.7505 - acc: 0.8152 - val_loss: 1.2687 - val_acc: 0.6400\n",
            "\n",
            "Epoch 00049: loss improved from 0.77643 to 0.75048, saving model to Sezen-Aksu-Epoch_49-Acc_0.82-Val_Acc_0.64.hdf5\n",
            "Epoch 50/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.7204 - acc: 0.8258 - val_loss: 1.2674 - val_acc: 0.6392\n",
            "\n",
            "Epoch 00050: loss improved from 0.75048 to 0.72044, saving model to Sezen-Aksu-Epoch_50-Acc_0.83-Val_Acc_0.64.hdf5\n",
            "Epoch 51/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.6942 - acc: 0.8344 - val_loss: 1.2606 - val_acc: 0.6421\n",
            "\n",
            "Epoch 00051: loss improved from 0.72044 to 0.69416, saving model to Sezen-Aksu-Epoch_51-Acc_0.83-Val_Acc_0.64.hdf5\n",
            "Epoch 52/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.6677 - acc: 0.8433 - val_loss: 1.2391 - val_acc: 0.6479\n",
            "\n",
            "Epoch 00052: loss improved from 0.69416 to 0.66767, saving model to Sezen-Aksu-Epoch_52-Acc_0.84-Val_Acc_0.65.hdf5\n",
            "Epoch 53/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.6420 - acc: 0.8515 - val_loss: 1.1933 - val_acc: 0.6647\n",
            "\n",
            "Epoch 00053: loss improved from 0.66767 to 0.64201, saving model to Sezen-Aksu-Epoch_53-Acc_0.85-Val_Acc_0.66.hdf5\n",
            "Epoch 54/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.6175 - acc: 0.8595 - val_loss: 1.1853 - val_acc: 0.6660\n",
            "\n",
            "Epoch 00054: loss improved from 0.64201 to 0.61746, saving model to Sezen-Aksu-Epoch_54-Acc_0.86-Val_Acc_0.67.hdf5\n",
            "Epoch 55/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.5940 - acc: 0.8671 - val_loss: 1.1521 - val_acc: 0.6792\n",
            "\n",
            "Epoch 00055: loss improved from 0.61746 to 0.59397, saving model to Sezen-Aksu-Epoch_55-Acc_0.87-Val_Acc_0.68.hdf5\n",
            "Epoch 56/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.5710 - acc: 0.8748 - val_loss: 1.1375 - val_acc: 0.6838\n",
            "\n",
            "Epoch 00056: loss improved from 0.59397 to 0.57102, saving model to Sezen-Aksu-Epoch_56-Acc_0.87-Val_Acc_0.68.hdf5\n",
            "Epoch 57/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.5457 - acc: 0.8831 - val_loss: 1.1214 - val_acc: 0.6894\n",
            "\n",
            "Epoch 00057: loss improved from 0.57102 to 0.54572, saving model to Sezen-Aksu-Epoch_57-Acc_0.88-Val_Acc_0.69.hdf5\n",
            "Epoch 58/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.5225 - acc: 0.8904 - val_loss: 1.0966 - val_acc: 0.6964\n",
            "\n",
            "Epoch 00058: loss improved from 0.54572 to 0.52247, saving model to Sezen-Aksu-Epoch_58-Acc_0.89-Val_Acc_0.70.hdf5\n",
            "Epoch 59/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.5038 - acc: 0.8962 - val_loss: 1.0856 - val_acc: 0.7016\n",
            "\n",
            "Epoch 00059: loss improved from 0.52247 to 0.50384, saving model to Sezen-Aksu-Epoch_59-Acc_0.90-Val_Acc_0.70.hdf5\n",
            "Epoch 60/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.4785 - acc: 0.9044 - val_loss: 1.0751 - val_acc: 0.7043\n",
            "\n",
            "Epoch 00060: loss improved from 0.50384 to 0.47848, saving model to Sezen-Aksu-Epoch_60-Acc_0.90-Val_Acc_0.70.hdf5\n",
            "Epoch 61/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.4586 - acc: 0.9106 - val_loss: 1.1855 - val_acc: 0.6639\n",
            "\n",
            "Epoch 00061: loss improved from 0.47848 to 0.45864, saving model to Sezen-Aksu-Epoch_61-Acc_0.91-Val_Acc_0.66.hdf5\n",
            "Epoch 62/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.4388 - acc: 0.9168 - val_loss: 1.0428 - val_acc: 0.7154\n",
            "\n",
            "Epoch 00062: loss improved from 0.45864 to 0.43880, saving model to Sezen-Aksu-Epoch_62-Acc_0.92-Val_Acc_0.72.hdf5\n",
            "Epoch 63/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.4184 - acc: 0.9225 - val_loss: 1.0117 - val_acc: 0.7266\n",
            "\n",
            "Epoch 00063: loss improved from 0.43880 to 0.41836, saving model to Sezen-Aksu-Epoch_63-Acc_0.92-Val_Acc_0.73.hdf5\n",
            "Epoch 64/150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.4001 - acc: 0.9281 - val_loss: 0.9917 - val_acc: 0.7354\n",
            "\n",
            "Epoch 00064: loss improved from 0.41836 to 0.40010, saving model to Sezen-Aksu-Epoch_64-Acc_0.93-Val_Acc_0.74.hdf5\n",
            "Epoch 65/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.3810 - acc: 0.9337 - val_loss: 0.9586 - val_acc: 0.7483\n",
            "\n",
            "Epoch 00065: loss improved from 0.40010 to 0.38102, saving model to Sezen-Aksu-Epoch_65-Acc_0.93-Val_Acc_0.75.hdf5\n",
            "Epoch 66/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.3626 - acc: 0.9387 - val_loss: 0.9433 - val_acc: 0.7550\n",
            "\n",
            "Epoch 00066: loss improved from 0.38102 to 0.36261, saving model to Sezen-Aksu-Epoch_66-Acc_0.94-Val_Acc_0.76.hdf5\n",
            "Epoch 67/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.3452 - acc: 0.9431 - val_loss: 0.9298 - val_acc: 0.7577\n",
            "\n",
            "Epoch 00067: loss improved from 0.36261 to 0.34523, saving model to Sezen-Aksu-Epoch_67-Acc_0.94-Val_Acc_0.76.hdf5\n",
            "Epoch 68/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.3312 - acc: 0.9469 - val_loss: 0.9319 - val_acc: 0.7564\n",
            "\n",
            "Epoch 00068: loss improved from 0.34523 to 0.33119, saving model to Sezen-Aksu-Epoch_68-Acc_0.95-Val_Acc_0.76.hdf5\n",
            "Epoch 69/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.3116 - acc: 0.9523 - val_loss: 0.9454 - val_acc: 0.7501\n",
            "\n",
            "Epoch 00069: loss improved from 0.33119 to 0.31165, saving model to Sezen-Aksu-Epoch_69-Acc_0.95-Val_Acc_0.75.hdf5\n",
            "Epoch 70/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.2971 - acc: 0.9560 - val_loss: 0.8846 - val_acc: 0.7744\n",
            "\n",
            "Epoch 00070: loss improved from 0.31165 to 0.29709, saving model to Sezen-Aksu-Epoch_70-Acc_0.96-Val_Acc_0.77.hdf5\n",
            "Epoch 71/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.2811 - acc: 0.9596 - val_loss: 0.8904 - val_acc: 0.7726\n",
            "\n",
            "Epoch 00071: loss improved from 0.29709 to 0.28112, saving model to Sezen-Aksu-Epoch_71-Acc_0.96-Val_Acc_0.77.hdf5\n",
            "Epoch 72/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.2679 - acc: 0.9628 - val_loss: 0.9186 - val_acc: 0.7594\n",
            "\n",
            "Epoch 00072: loss improved from 0.28112 to 0.26786, saving model to Sezen-Aksu-Epoch_72-Acc_0.96-Val_Acc_0.76.hdf5\n",
            "Epoch 73/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.2546 - acc: 0.9659 - val_loss: 0.8196 - val_acc: 0.7997\n",
            "\n",
            "Epoch 00073: loss improved from 0.26786 to 0.25456, saving model to Sezen-Aksu-Epoch_73-Acc_0.97-Val_Acc_0.80.hdf5\n",
            "Epoch 74/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.2406 - acc: 0.9684 - val_loss: 0.7905 - val_acc: 0.8125\n",
            "\n",
            "Epoch 00074: loss improved from 0.25456 to 0.24056, saving model to Sezen-Aksu-Epoch_74-Acc_0.97-Val_Acc_0.81.hdf5\n",
            "Epoch 75/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.2287 - acc: 0.9707 - val_loss: 0.8183 - val_acc: 0.7996\n",
            "\n",
            "Epoch 00075: loss improved from 0.24056 to 0.22866, saving model to Sezen-Aksu-Epoch_75-Acc_0.97-Val_Acc_0.80.hdf5\n",
            "Epoch 76/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.2150 - acc: 0.9739 - val_loss: 0.7663 - val_acc: 0.8210\n",
            "\n",
            "Epoch 00076: loss improved from 0.22866 to 0.21504, saving model to Sezen-Aksu-Epoch_76-Acc_0.97-Val_Acc_0.82.hdf5\n",
            "Epoch 77/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.2050 - acc: 0.9757 - val_loss: 0.7568 - val_acc: 0.8278\n",
            "\n",
            "Epoch 00077: loss improved from 0.21504 to 0.20500, saving model to Sezen-Aksu-Epoch_77-Acc_0.98-Val_Acc_0.83.hdf5\n",
            "Epoch 78/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1941 - acc: 0.9776 - val_loss: 0.7379 - val_acc: 0.8325\n",
            "\n",
            "Epoch 00078: loss improved from 0.20500 to 0.19411, saving model to Sezen-Aksu-Epoch_78-Acc_0.98-Val_Acc_0.83.hdf5\n",
            "Epoch 79/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.1819 - acc: 0.9796 - val_loss: 0.7785 - val_acc: 0.8148\n",
            "\n",
            "Epoch 00079: loss improved from 0.19411 to 0.18190, saving model to Sezen-Aksu-Epoch_79-Acc_0.98-Val_Acc_0.81.hdf5\n",
            "Epoch 80/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1729 - acc: 0.9811 - val_loss: 0.7969 - val_acc: 0.8051\n",
            "\n",
            "Epoch 00080: loss improved from 0.18190 to 0.17287, saving model to Sezen-Aksu-Epoch_80-Acc_0.98-Val_Acc_0.81.hdf5\n",
            "Epoch 81/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1638 - acc: 0.9828 - val_loss: 0.6884 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00081: loss improved from 0.17287 to 0.16381, saving model to Sezen-Aksu-Epoch_81-Acc_0.98-Val_Acc_0.85.hdf5\n",
            "Epoch 82/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1544 - acc: 0.9844 - val_loss: 0.6888 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00082: loss improved from 0.16381 to 0.15442, saving model to Sezen-Aksu-Epoch_82-Acc_0.98-Val_Acc_0.85.hdf5\n",
            "Epoch 83/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1473 - acc: 0.9853 - val_loss: 0.6735 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00083: loss improved from 0.15442 to 0.14727, saving model to Sezen-Aksu-Epoch_83-Acc_0.99-Val_Acc_0.86.hdf5\n",
            "Epoch 84/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1379 - acc: 0.9867 - val_loss: 0.6413 - val_acc: 0.8730\n",
            "\n",
            "Epoch 00084: loss improved from 0.14727 to 0.13786, saving model to Sezen-Aksu-Epoch_84-Acc_0.99-Val_Acc_0.87.hdf5\n",
            "Epoch 85/150\n",
            "306385/306385 [==============================] - 121s 395us/step - loss: 0.1308 - acc: 0.9877 - val_loss: 0.6250 - val_acc: 0.8816\n",
            "\n",
            "Epoch 00085: loss improved from 0.13786 to 0.13082, saving model to Sezen-Aksu-Epoch_85-Acc_0.99-Val_Acc_0.88.hdf5\n",
            "Epoch 86/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1231 - acc: 0.9887 - val_loss: 0.6894 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00086: loss improved from 0.13082 to 0.12313, saving model to Sezen-Aksu-Epoch_86-Acc_0.99-Val_Acc_0.85.hdf5\n",
            "Epoch 87/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1169 - acc: 0.9893 - val_loss: 0.5855 - val_acc: 0.8945\n",
            "\n",
            "Epoch 00087: loss improved from 0.12313 to 0.11689, saving model to Sezen-Aksu-Epoch_87-Acc_0.99-Val_Acc_0.89.hdf5\n",
            "Epoch 88/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1097 - acc: 0.9902 - val_loss: 0.6042 - val_acc: 0.8883\n",
            "\n",
            "Epoch 00088: loss improved from 0.11689 to 0.10966, saving model to Sezen-Aksu-Epoch_88-Acc_0.99-Val_Acc_0.89.hdf5\n",
            "Epoch 89/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.1039 - acc: 0.9910 - val_loss: 0.6456 - val_acc: 0.8702\n",
            "\n",
            "Epoch 00089: loss improved from 0.10966 to 0.10394, saving model to Sezen-Aksu-Epoch_89-Acc_0.99-Val_Acc_0.87.hdf5\n",
            "Epoch 90/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.0978 - acc: 0.9917 - val_loss: 0.5852 - val_acc: 0.8967\n",
            "\n",
            "Epoch 00090: loss improved from 0.10394 to 0.09783, saving model to Sezen-Aksu-Epoch_90-Acc_0.99-Val_Acc_0.90.hdf5\n",
            "Epoch 91/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.0922 - acc: 0.9923 - val_loss: 0.5965 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00091: loss improved from 0.09783 to 0.09221, saving model to Sezen-Aksu-Epoch_91-Acc_0.99-Val_Acc_0.89.hdf5\n",
            "Epoch 92/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.0874 - acc: 0.9926 - val_loss: 0.5548 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00092: loss improved from 0.09221 to 0.08735, saving model to Sezen-Aksu-Epoch_92-Acc_0.99-Val_Acc_0.91.hdf5\n",
            "Epoch 93/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.0836 - acc: 0.9929 - val_loss: 0.5662 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00093: loss improved from 0.08735 to 0.08358, saving model to Sezen-Aksu-Epoch_93-Acc_0.99-Val_Acc_0.90.hdf5\n",
            "Epoch 94/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.0797 - acc: 0.9932 - val_loss: 0.5616 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00094: loss improved from 0.08358 to 0.07969, saving model to Sezen-Aksu-Epoch_94-Acc_0.99-Val_Acc_0.90.hdf5\n",
            "Epoch 95/150\n",
            "306385/306385 [==============================] - 121s 394us/step - loss: 0.0760 - acc: 0.9936 - val_loss: 0.5620 - val_acc: 0.9041\n",
            "\n",
            "Epoch 00095: loss improved from 0.07969 to 0.07599, saving model to Sezen-Aksu-Epoch_95-Acc_0.99-Val_Acc_0.90.hdf5\n",
            "Epoch 00095: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kgNiAP9E7H4_",
        "colab": {},
        "outputId": "d13f65fa-ed9b-48ca-ee4c-9fe7cb609c77"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(14,3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "files.download('Sezen-Aksu-Epoch_95-Acc_0.99-Val_Acc_0.90.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RZgVQZrCJNqG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model ağırlıklarının yüklenmesi :\n",
        "wights_file = 'Sezen-Aksu-Epoch_95-Acc_0.99-Val_Acc_0.90.hdf5' \n",
        "model.load_weights(wights_file)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = adam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ThRgN3tAJNqJ",
        "outputId": "c708f3fb-1d2a-4395-eb34-b47281585d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "# rastgele bir şarkı öbeği seç:\n",
        "start = np.random.randint(0, len(data_X)-1)\n",
        "pattern = data_X[start]\n",
        "print('Seçilen söz : ')\n",
        "print(\"\\\"\",''.join([int_chars[value] for value in pattern]), \"\\\"\\n\")\n",
        "# karakter olarak oluşturulmak istenen şarkı uunluğu\n",
        "generated_characters = 300\n",
        "# karakter üret:\n",
        "for i in range(generated_characters):\n",
        "    x = np.reshape(pattern, ( 1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x,verbose = 0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_chars[index]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print('\\nBitti')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seçilen söz : \n",
            "\" ler var\n",
            "gitme dur daha şimdiden  \"\n",
            "\n",
            "deliler gibi özledim\n",
            "i̇kimiz içinde doğru olan böylesi git\n",
            "i̇nan bana sandığın kadar bile haçırım var\n",
            "van yaylar\n",
            "hayırsıl tüsü dklerin dükülden girki gelen kardığınmeyin\n",
            "bereen o çücül tür gelme\n",
            "teni gördüm uan\n",
            "bir dünya bir tırd gön eelir\n",
            "yat oomadak tenenen aşkın oldum dilere gamiı yon\n",
            "yuruş malpi\n",
            "Bitti\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C6VmvPXpEAFS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l-hE8A6GEAFU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# colab:\n",
        "uploaded = files.upload()\n",
        "all_files = [(name, os.path.getmtime(name)) for name in os.listdir()]\n",
        "file_path = sorted(all_files, key=lambda x: -x[1])[0][0]\n",
        "# lokal:\n",
        "#file_path='Sezen Aksu Only Lyrics.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QXsvXLx1EAFV",
        "colab_type": "code",
        "colab": {},
        "outputId": "38161037-0f2f-4729-977e-1cd10f4bff5e"
      },
      "cell_type": "code",
      "source": [
        "model_name = 'Sezen_Aksu_textgenrnn_Model'\n",
        "\n",
        "textgen = textgenrnn(name=model_name)\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "train_function(\n",
        "    file_path=,file_path\n",
        "    new_model=True,\n",
        "    num_epochs=100,\n",
        "    gen_epochs=25,\n",
        "    batch_size=1024,\n",
        "    train_size=0.9,\n",
        "    dropout=0.5,\n",
        "    max_gen_length=300,\n",
        "    validation=True,\n",
        "    is_csv=False,\n",
        "    rnn_layers=4,\n",
        "    rnn_size=32,\n",
        "    rnn_bidirectional=True,\n",
        "    max_length=15,\n",
        "    dim_embeddings=100,\n",
        "    word_level=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12,125 texts collected.\n",
            "Training new model w/ 4-layer, 32-cell Bidirectional LSTMs\n",
            "Training on 307,386 character sequences.\n",
            "Epoch 1/100\n",
            "300/300 [==============================] - 28s 94ms/step - loss: 2.3329 - val_loss: 2.0181\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - 27s 90ms/step - loss: 1.9702 - val_loss: 1.8434\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - 27s 89ms/step - loss: 1.8227 - val_loss: 1.7378\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - 26s 86ms/step - loss: 1.7242 - val_loss: 1.6548\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.6622 - val_loss: 1.6111\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 1.6084 - val_loss: 1.5779\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - 27s 91ms/step - loss: 1.5716 - val_loss: 1.5392\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.5371 - val_loss: 1.5203\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 1.5072 - val_loss: 1.4839\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.4812 - val_loss: 1.4739\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - 24s 79ms/step - loss: 1.4544 - val_loss: 1.4574\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.4351 - val_loss: 1.4370\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.4104 - val_loss: 1.4219\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - 27s 91ms/step - loss: 1.3948 - val_loss: 1.4055\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 1.3758 - val_loss: 1.3978\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - 27s 89ms/step - loss: 1.3614 - val_loss: 1.3851\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - 24s 80ms/step - loss: 1.3469 - val_loss: 1.3719\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - 26s 88ms/step - loss: 1.3269 - val_loss: 1.3676\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - 26s 87ms/step - loss: 1.3164 - val_loss: 1.3459\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - 26s 85ms/step - loss: 1.3055 - val_loss: 1.3481A: 1s - loss - ETA: 0s - l\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.2909 - val_loss: 1.3401\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - 26s 86ms/step - loss: 1.2786 - val_loss: 1.3220\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - 26s 85ms/step - loss: 1.2658 - val_loss: 1.3194\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.2554 - val_loss: 1.3188\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.2445 - val_loss: 1.3171\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\"ne olur gel bana gel bana gel bana gel bana gel gel bana gel bana haydi gel bana gel bana gel bana gel bana gel bana kaldırım sen gel\n",
            "\n",
            "\"ne olur gözlerini o gözümde\n",
            "\n",
            "\"ne olur geldi yolları\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\"ne zaman bulunurum\n",
            "\n",
            "\"ne yanın açılmış ah istedim\n",
            "\n",
            "\"ne hata tam kaldır kısa mı kırıldı\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "sen purak çeker tefap bıkmışım ki içe hey\n",
            "\n",
            "senden sen ömür\n",
            "\n",
            "\"“kendin kardeden tüm gecede\n",
            "\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - 24s 81ms/step - loss: 1.2358 - val_loss: 1.2943\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - 26s 85ms/step - loss: 1.2247 - val_loss: 1.2977\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.2150 - val_loss: 1.3002\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.2028 - val_loss: 1.2883\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - 25s 85ms/step - loss: 1.1998 - val_loss: 1.2737\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.1879 - val_loss: 1.2757\n",
            "Epoch 32/100\n",
            "300/300 [==============================] - 26s 85ms/step - loss: 1.1821 - val_loss: 1.2550\n",
            "Epoch 33/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 1.1731 - val_loss: 1.2615\n",
            "Epoch 34/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 1.1656 - val_loss: 1.2603\n",
            "Epoch 35/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.1566 - val_loss: 1.2490\n",
            "Epoch 36/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.1490 - val_loss: 1.2439\n",
            "Epoch 37/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.1429 - val_loss: 1.2461\n",
            "Epoch 38/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.1330 - val_loss: 1.2305\n",
            "Epoch 39/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.1308 - val_loss: 1.2371\n",
            "Epoch 40/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.1222 - val_loss: 1.2277\n",
            "Epoch 41/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 1.1174 - val_loss: 1.2242\n",
            "Epoch 42/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.1093 - val_loss: 1.2273\n",
            "Epoch 43/100\n",
            "300/300 [==============================] - 25s 85ms/step - loss: 1.1051 - val_loss: 1.2166\n",
            "Epoch 44/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 1.0956 - val_loss: 1.2083\n",
            "Epoch 45/100\n",
            "300/300 [==============================] - 26s 87ms/step - loss: 1.0908 - val_loss: 1.2020\n",
            "Epoch 46/100\n",
            "300/300 [==============================] - 25s 85ms/step - loss: 1.0864 - val_loss: 1.2065\n",
            "Epoch 47/100\n",
            "300/300 [==============================] - 25s 85ms/step - loss: 1.0792 - val_loss: 1.1979\n",
            "Epoch 48/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.0732 - val_loss: 1.2007\n",
            "Epoch 49/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.0695 - val_loss: 1.1923\n",
            "Epoch 50/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.0601 - val_loss: 1.1965\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\"ne olur gerçekten\n",
            "\n",
            "\"ne olur gerçekten\n",
            "\n",
            "\"ne olur gerçek\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\"unuttun altından taşlarıma\n",
            "\n",
            "\"lale devri başlar gibi\n",
            "\n",
            "\"ne olur gibi döner miyim\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "\"\"\"\n",
            "\n",
            "ne sevmek istedim sezen gitmiş fahval mısın\n",
            "\n",
            "\"altındak güldüm, gitme gitme\n",
            "\n",
            "Epoch 51/100\n",
            "300/300 [==============================] - 24s 80ms/step - loss: 1.0609 - val_loss: 1.1851\n",
            "Epoch 52/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.0517 - val_loss: 1.1803\n",
            "Epoch 53/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.0476 - val_loss: 1.1838\n",
            "Epoch 54/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.0410 - val_loss: 1.1798\n",
            "Epoch 55/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 1.0382 - val_loss: 1.1789\n",
            "Epoch 56/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 1.0324 - val_loss: 1.1628\n",
            "Epoch 57/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 1.0301 - val_loss: 1.1732\n",
            "Epoch 58/100\n",
            "300/300 [==============================] - 25s 85ms/step - loss: 1.0218 - val_loss: 1.1635\n",
            "Epoch 59/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.0180 - val_loss: 1.1604\n",
            "Epoch 60/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 1.0140 - val_loss: 1.1646\n",
            "Epoch 61/100\n",
            "300/300 [==============================] - 26s 85ms/step - loss: 1.0078 - val_loss: 1.1555\n",
            "Epoch 62/100\n",
            "300/300 [==============================] - 26s 87ms/step - loss: 1.0040 - val_loss: 1.1546\n",
            "Epoch 63/100\n",
            "300/300 [==============================] - 26s 87ms/step - loss: 1.0028 - val_loss: 1.1472\n",
            "Epoch 64/100\n",
            "300/300 [==============================] - 26s 85ms/step - loss: 0.9935 - val_loss: 1.1350\n",
            "Epoch 65/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 0.9913 - val_loss: 1.1414\n",
            "Epoch 66/100\n",
            "300/300 [==============================] - 26s 86ms/step - loss: 0.9873 - val_loss: 1.1464\n",
            "Epoch 67/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.9822 - val_loss: 1.1321\n",
            "Epoch 68/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.9775 - val_loss: 1.1332\n",
            "Epoch 69/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 24s 81ms/step - loss: 0.9737 - val_loss: 1.1283\n",
            "Epoch 70/100\n",
            "300/300 [==============================] - 24s 80ms/step - loss: 0.9720 - val_loss: 1.1356\n",
            "Epoch 71/100\n",
            "300/300 [==============================] - 24s 81ms/step - loss: 0.9650 - val_loss: 1.1256\n",
            "Epoch 72/100\n",
            "300/300 [==============================] - 24s 80ms/step - loss: 0.9636 - val_loss: 1.1338\n",
            "Epoch 73/100\n",
            "300/300 [==============================] - 24s 80ms/step - loss: 0.9565 - val_loss: 1.1188\n",
            "Epoch 74/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 0.9545 - val_loss: 1.1203\n",
            "Epoch 75/100\n",
            "300/300 [==============================] - 24s 81ms/step - loss: 0.9501 - val_loss: 1.1198\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\"ne olur kalp kavuşmakta sen dayanırsın\n",
            "\n",
            "\"ne olur kapıyı\n",
            "\n",
            "\"ne olur kalp kavuşmakta sen dayanırsın\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\"lk gün gibi, ilk gün gibi saklarını\n",
            "\n",
            "\"lk gün gibi, ilk gün gibi seni özlerimi\n",
            "\n",
            "\"ne başım ağlar\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "\"köle, kalmış kendini yine gönlün\n",
            "\n",
            "\"tert diye dolmadan beyaz bir pavuncak sıkıldım\n",
            "\n",
            "\"polak geçti bıraktığın kadere buluruz\n",
            "\n",
            "Epoch 76/100\n",
            "300/300 [==============================] - 23s 78ms/step - loss: 0.9478 - val_loss: 1.1160\n",
            "Epoch 77/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.9432 - val_loss: 1.1161\n",
            "Epoch 78/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.9416 - val_loss: 1.1094\n",
            "Epoch 79/100\n",
            "300/300 [==============================] - 24s 82ms/step - loss: 0.9366 - val_loss: 1.1077\n",
            "Epoch 80/100\n",
            "300/300 [==============================] - 24s 81ms/step - loss: 0.9325 - val_loss: 1.1095\n",
            "Epoch 81/100\n",
            "300/300 [==============================] - 25s 85ms/step - loss: 0.9306 - val_loss: 1.1090\n",
            "Epoch 82/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 0.9266 - val_loss: 1.1003\n",
            "Epoch 83/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.9229 - val_loss: 1.1013\n",
            "Epoch 84/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.9203 - val_loss: 1.0881\n",
            "Epoch 85/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 0.9178 - val_loss: 1.1032\n",
            "Epoch 86/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.9143 - val_loss: 1.0943\n",
            "Epoch 87/100\n",
            "300/300 [==============================] - 25s 82ms/step - loss: 0.9106 - val_loss: 1.0921\n",
            "Epoch 88/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.9101 - val_loss: 1.0920\n",
            "Epoch 89/100\n",
            "300/300 [==============================] - 26s 87ms/step - loss: 0.9049 - val_loss: 1.0895\n",
            "Epoch 90/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 0.9012 - val_loss: 1.0843\n",
            "Epoch 91/100\n",
            "300/300 [==============================] - 25s 84ms/step - loss: 0.8969 - val_loss: 1.0883\n",
            "Epoch 92/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.8953 - val_loss: 1.0830\n",
            "Epoch 93/100\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.8956 - val_loss: 1.0857\n",
            "Epoch 94/100\n",
            "300/300 [==============================] - 27s 89ms/step - loss: 0.8914 - val_loss: 1.0780\n",
            "Epoch 95/100\n",
            "300/300 [==============================] - 29s 96ms/step - loss: 0.8869 - val_loss: 1.0847\n",
            "Epoch 96/100\n",
            "300/300 [==============================] - 29s 96ms/step - loss: 0.8871 - val_loss: 1.0805\n",
            "Epoch 97/100\n",
            "300/300 [==============================] - 27s 90ms/step - loss: 0.8826 - val_loss: 1.0812\n",
            "Epoch 98/100\n",
            "300/300 [==============================] - 26s 86ms/step - loss: 0.8827 - val_loss: 1.0758\n",
            "Epoch 99/100\n",
            "300/300 [==============================] - 27s 91ms/step - loss: 0.8802 - val_loss: 1.0684: \n",
            "Epoch 100/100\n",
            "300/300 [==============================] - 38s 128ms/step - loss: 0.8782 - val_loss: 1.0814\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\"nerde kaldı o da gelir geçer geçer bir kere belki yok\n",
            "\n",
            "\"unuttun karaya vurdum aman\n",
            "\n",
            "\"ne yana baksam gözlerine göz değil\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "ne olur etmedi, rahat et!\"\n",
            "\n",
            "\"ne olur geri dostum düzeneğin\n",
            "\n",
            "\"nerdek bir hayat bulur yerinden\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "eğretiyorsan eğer\n",
            "\n",
            "\"üpsal olsun dok, seni yine gündüz, dut hadi\n",
            "\n",
            "\"ne olur sıkı gidesinsin insancı gözlerinde\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kOsP12tBEAFY",
        "colab_type": "code",
        "colab": {},
        "outputId": "e90940ba-8ae8-44fe-b8af-66d22e550795"
      },
      "cell_type": "code",
      "source": [
        "print(textgen.model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 15)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 15, 100)      6200        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (SpatialDropout1D)      (None, 15, 100)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "rnn_1 (Bidirectional)           (None, 15, 64)       34304       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "rnn_2 (Bidirectional)           (None, 15, 64)       25088       rnn_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "rnn_3 (Bidirectional)           (None, 15, 64)       25088       rnn_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "rnn_4 (Bidirectional)           (None, 15, 64)       25088       rnn_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "rnn_concat (Concatenate)        (None, 15, 356)      0           dropout[0][0]                    \n",
            "                                                                 rnn_1[0][0]                      \n",
            "                                                                 rnn_2[0][0]                      \n",
            "                                                                 rnn_3[0][0]                      \n",
            "                                                                 rnn_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "attention (AttentionWeightedAve (None, 356)          356         rnn_concat[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 62)           22134       attention[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 138,258\n",
            "Trainable params: 138,258\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "WnNNNyZkEAFa",
        "colab_type": "code",
        "colab": {},
        "outputId": "277c95f7-b376-4562-858e-dd0238dc69e8"
      },
      "cell_type": "code",
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'files' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-73-240cf3d7c947>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}_weights.hdf5'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}_vocab.json'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}_config.json'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "x_qvNoIaEAFd",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb058511-8c1a-4158-ef8b-77e2ee234d0f"
      },
      "cell_type": "code",
      "source": [
        "textgen = textgenrnn(weights_path='Sezen_Aksu_textgenrnn_Model_weights.hdf5',\n",
        "                       vocab_path='Sezen_Aksu_textgenrnn_Model_vocab.json',\n",
        "                       config_path='Sezen_Aksu_textgenrnn_Model_config.json')\n",
        "generated_characters = 300\n",
        "textgen.generate_samples(15)\n",
        "textgen.generate_to_file('lyrics.txt', 300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\"lk gün gibi, ilk gün gibi seni beklerim de gırtlak, pufidi kandil, tumba yatak\"\n",
            "\n",
            "\"ne olur günahlarım yaşamak\n",
            "\n",
            "\"ne olur ki yıllarca yalan kattık\n",
            "\n",
            "\"nsan, sevgi kokuyorsun\"\n",
            "\n",
            "\"ne olur kapılarıma\n",
            "\n",
            "\"ne olur kulağıma\n",
            "\n",
            "\"nerde saydım sevişler\n",
            "\n",
            "\"ne yana bi beni sarardı sana kapılarıma sarar ve dayanırsın\n",
            "\n",
            "\"ne yangınlar bir de ateşte\n",
            "\n",
            "\"nerde kalbim, aahh kalbim!\"\n",
            "\n",
            "\"ne olur ki aşk için her gece günde\n",
            "\n",
            "\"ne olur bir kuş sanki\n",
            "\n",
            "\"nerde sevgili, bebekseyim\"\n",
            "\n",
            "\"nsan, sevgi kokuyorsun\"\n",
            "\n",
            "\"nsan, sevgi kokuyorsun\"\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\"nsan, sevgi kokuyorsun\"\n",
            "\n",
            "\"tevâş taşkın kısası\n",
            "\n",
            "\"ne hata tanımıyorum\n",
            "\n",
            "\"ne bana uyursa da şart değil demiştim\n",
            "\n",
            "\"lk gün gibi, ilk gün gibi seni bekler çek git bile yaşadığım\n",
            "\n",
            "\"titremem dar beni yak kim\n",
            "\n",
            "\"lk gün gibi, ilk gün gibi seni beklerim başlar günler gibi\n",
            "\n",
            "\"tara bu hal tuzak yüzünü uyudan mı aldım\n",
            "\n",
            "\"lale devri çocuklarım doğru büyük kalaşlar\n",
            "\n",
            "\"tek kırın gibi özlerimi\n",
            "\n",
            "\"tepedan bir dediğine uymuyor senin\n",
            "\n",
            "\"tek şey anımsa bile\n",
            "\n",
            "\"nsan, sevgi kokuyorsun\"\n",
            "\n",
            "\"nsan, sevgi bu yağmur\n",
            "\n",
            "\"unuttum kendi de fohitsadım sensin\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "çimdekini sen öğrendim başıma\n",
            "\n",
            "\"kısa soru dokunmak\n",
            "\n",
            "\"şimal ol önemlik de\n",
            "\n",
            "koyun bana biraz nasip olurum\n",
            "\n",
            "sevdiğim siner süz gibi bir çaldır değil evde\n",
            "\n",
            "\"tatlı güçlü peşer diye değildim hep bu kadar değil her zaman\n",
            "\n",
            "\"nsan, sevgi kokuyorsa\n",
            "\n",
            "niye diye yiyesim var\n",
            "\n",
            "ap neden bozmayından gülümse karargünden kaldı gitti\n",
            "\n",
            "\"ne yanlıyı\n",
            "\n",
            "\"tıplı gülerken\n",
            "\n",
            "\"en çocuka da küllense\n",
            "\n",
            "hergün çizgisizlik bir şey acıma beni bırak\n",
            "\n",
            "\"nsan sonran gülümsen uzaklığım sensin\n",
            "\n",
            "\"tanrı gümühah biraz ne kadar\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "generate_to_file() takes 2 positional arguments but 3 were given",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-78-c4b9525cf605>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgenerated_characters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtextgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtextgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lyrics.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: generate_to_file() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    }
  ]
}
